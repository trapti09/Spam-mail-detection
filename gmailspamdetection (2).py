# -*- coding: utf-8 -*-
"""GmailSpamDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IDmmbNlUYhe818O9bYTX0rlogQFzhhrA

# Spam Detection with Natural Language Processing using NLTK
"""

import numpy as np
import pandas as pd
import nltk
nltk.download('wordnet')
nltk.download('stopwords')
from sklearn import metrics
from sklearn.metrics import precision_score
import matplotlib.pyplot as plt

import chardet
with open("spam.csv", 'rb') as rawdata:
    result = chardet.detect(rawdata.read(100000))
print(result)

"""## 1) Loading Data Set"""

dt = pd.read_csv('spam.csv' , encoding = 'Windows-1252')
dt.head()

dt = pd.DataFrame(dt)
dt.rename(columns={"v1": 'type', "v2": 'text'}, inplace = True)
dt.head(10)

dt.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace = True)

dt['spam'] = dt['type'].map( {'spam': 1, 'ham': 0} ).astype(int)
dt.head(5)

print("COLUMS IN THE GIVEN DATA:")
for col in dt.columns:
    print(col)

t=len(dt['type'])
print("NO OF ROWS IN REVIEW COLUMN:",t)
t=len(dt['text'])
print("NO OF ROWS IN liked COLUMN:",t)

"""## 2) Tokenization"""

#before
dt['text'][1]

def tokenizer(text):
    return text.split()

dt['text']=dt['text'].apply(tokenizer)

#after
dt['text'][1]

#before
dt['text'][1]

"""## 3) Stemming"""

from nltk.stem.snowball import SnowballStemmer
porter = SnowballStemmer("english", ignore_stopwords=False)

def stem_it(text):
    return [porter.stem(word) for word in text]

dt['text']=dt['text'].apply(stem_it)

#after stemming
dt['text'][1]

"""## 4) Lemmatization"""

#before
dt['text'][100]

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()

def lemmit_it(text):
    return [lemmatizer.lemmatize(word, pos ="a") for word in text]

dt['text']=dt['text'].apply(lemmit_it)

#before
dt['text'][100]

"""## 5) Stopword Removal"""

#before
dt['text'][100]

from nltk.corpus import stopwords
stop_words = stopwords.words('english')

def stop_it(text):
    review = [word for word in text if not word in stop_words ]
    return review

dt['text']=dt['text'].apply(stop_it)

#after
dt['text'][100]

dt.head(100)

dt['text']=dt['text'].apply(' '.join)

dt.head()

"""##  6) Transform Text Data into TDF /TF-IDF Vectors   """

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf=TfidfVectorizer()
y=dt.spam.values
x=tfidf.fit_transform(dt['text'])

from sklearn.model_selection import train_test_split
x_train,x_text,y_train,y_text=train_test_split(x,y,random_state=1,test_size=0.2,shuffle=False)

"""## 7) Applying Classifiers and Evaluating

### `Logistic Regression`
"""

from sklearn.linear_model import LogisticRegression
clf=LogisticRegression()
clf.fit(x_train,y_train)
y_pred=clf.predict(x_text)
from sklearn.metrics import accuracy_score
acc_log = accuracy_score(y_pred, y_text)*100
acc_c = metrics.confusion_matrix(y_text, y_pred)
pre_sc=precision_score(y_text,y_pred)
print("accuracy:",acc_log )
print("confusion matrix:",acc_c)
print("precision score:",pre_sc)
from sklearn.metrics import classification_report
print(classification_report(y_text, y_pred))

"""### `LinearSVC Accuracy`"""

from sklearn.svm import LinearSVC

linear_svc = LinearSVC(random_state=0)
linear_svc.fit(x_train, y_train)
y_pred = linear_svc.predict(x_text)
acc_linear_svc =accuracy_score(y_pred, y_text) * 100
acc_cm = metrics.confusion_matrix(y_text, y_pred)
pre_sc=precision_score(y_text,y_pred)
print("accuracy:",acc_linear_svc)
print("confusion matrix:",acc_cm)
print("precision score:",pre_sc)
from sklearn.metrics import classification_report
print(classification_report(y_text, y_pred))

"""### `Multinomial NB`"""

from sklearn.naive_bayes import MultinomialNB

mnb = MultinomialNB()
mnb.fit(x_train,y_train)
y_pred = mnb.predict(x_text)
acc_mNB = accuracy_score(y_pred, y_text)*100
acc_cm = metrics.confusion_matrix(y_text, y_pred)
pre_sc=precision_score(y_text,y_pred)
print("accuracy:",acc_mNB )
print("confusion matrix:",acc_cm)
print("precision score:",pre_sc)
from sklearn.metrics import classification_report
print(classification_report(y_text, y_pred))

"""### `Bernoulli NB`"""

from sklearn.naive_bayes import BernoulliNB

bnb = BernoulliNB()
bnb.fit(x_train,y_train)
y_pred = bnb.predict(x_text)
acc_bNB = accuracy_score(y_pred, y_text)*100
acc_cm = metrics.confusion_matrix(y_text, y_pred)
pre_sc=precision_score(y_text,y_pred)
print("accuracy:",acc_bNB )
print("confusion matrix:",acc_cm)
print("precision score:",pre_sc)
from sklearn.metrics import classification_report
print(classification_report(y_text, y_pred))

"""### `Decision Tree Classifier`"""

from sklearn.tree import DecisionTreeClassifier
dtc=DecisionTreeClassifier()
dtc.fit(x_train,y_train)
y_pred=dtc.predict(x_text)
from sklearn.metrics import accuracy_score
acc_log = accuracy_score(y_pred, y_text)*100
acc_c = metrics.confusion_matrix(y_text, y_pred)
pre_sc=precision_score(y_text,y_pred)
print("accuracy:",acc_log )
print("confusion matrix:",acc_c)
print("precision score:",pre_sc)
from sklearn.metrics import classification_report
print(classification_report(y_text, y_pred))

"""### `Bagging Classifier`"""

from sklearn.ensemble import BaggingClassifier

bag_c=BaggingClassifier()
bag_c.fit(x_train,y_train)
y_pred=bag_c.predict(x_text)
from sklearn.metrics import accuracy_score
acc_log = accuracy_score(y_pred, y_text)*100
acc_c = metrics.confusion_matrix(y_text, y_pred)
pre_sc=precision_score(y_text,y_pred)
print("accuracy:",acc_log )
print("confusion matrix:",acc_c)
print("precision score:",pre_sc)
from sklearn.metrics import classification_report
print(classification_report(y_text, y_pred))

Models=['logisticreg','LinearSVC','MultinomailNB','BernoulliNB','DecisionTree','Bagging']
accuracy=[96.0538,97.6681,96.7713,98.4753,96.6816,97.2197]
plt.plot(batch_size,accuracy,'b-o',label='Accuracy over batch size for 1000 iterations');
plt.xlabel('Batch Size')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

Models=['logisticreg','LinearSVC','MultinomailNB','BernoulliNB','DecisionTree','Bagging']
Precision = [0.9902,0.9685, 1.0, 0.9848, 0.8913, 0.9212]
plt.bar(Models,Precision,color="red",width=0.2);
plt.xlabel('Models')
plt.ylabel('Precision')
plt.title('Precision score representation of models')
plt.show()

barWidth = 0.25
fig = plt.subplots(figsize =(12, 8))
Accuracy = [96.0538,97.6681,96.7713,98.4753,96.6816,97.2197]
Precision = [99.02, 96.85, 100.0, 98.48, 89.13, 92.12]
br1 = np.arange(len(Accuracy))
br2 = [x + barWidth for x in br1]
# Make the plot
plt.bar(br1, Accuracy, color ='y', width = barWidth,
        edgecolor ='grey', label ='Accuracy')
plt.bar(br2, Precision, color ='g', width = barWidth,
        edgecolor ='grey', label ='Precision')

# Adding Xticks
plt.xlabel('Models', fontweight ='bold', fontsize = 15)
plt.ylabel('Decision Parameters', fontweight ='bold', fontsize = 15)
plt.xticks([r + barWidth for r in range(len(Accuracy))],
        ['logisticreg','LinearSVC','MultinomailNB','BernoulliNB','DecisionTree','Bagging'])

plt.legend()
plt.show()